devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(copyseparator)
devtools::document()
devtools::document()
library(copyseparator)
copy_validate("All_final_copies.fasta",2,300)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
'R.utils'::on
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
verbose <- Verbose(threshold=-1)
if (verbose) { cat(verbose, "A v-comment log message"); }
cat("Hello world")
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
devtools::document()
copy_separate("Sucker.fasta",2,300)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
devtools::document()
library(copyseparator)
devtools::document()
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
on(verbose)
sink("log.txt", append=FALSE, split=TRUE) # begin to record log
error_log_function <- function() {
cat(geterrmessage(), file="Error_log.txt", append=T)
}
filename="Sucker.fasta"
copy_number=2
read_length=300
overlap=225
lower_threshold=0.45
if (copy_number<=1) stop ("The expected copy number must be a number larger than one!")
if (read_length<250) warning ("This method is designed for read length 250bp or longer. Short reads can easily result in chimeric sequences.")
NGS_reads <- read.fasta(file = filename,seqtype = "DNA", as.string = TRUE,forceDNAtolower = FALSE,set.attributes = FALSE)
total_reads <- length(NGS_reads); cat(paste0("Total number of reads imported = ",total_reads,"\n"))
alignment_length <- nchar(NGS_reads[[1]]); cat(paste0("Length of the alignment = ",alignment_length,"\n"))
cat(paste0("Read length = ",read_length,"\n"))
cat(paste0("Overlap between adjacent subsets = ",overlap,"\n"))
if (overlap>=read_length) stop("Overlap between adjacent subsets must be smaller than the read length!")
begin_number <- seq(1,alignment_length-200, by=read_length-overlap); cat("Beginning position of each subset","\n"); cat(begin_number,"\n")
end_number <- begin_number+read_length-1; cat("Ending position of each subset\n"); cat(end_number,"\n")
number_of_subsets <- length(begin_number); cat(paste0("Total number of subsets = ",number_of_subsets,"\n"))
for (i in begin_number) {
subset_original <- lapply(1:total_reads, function(x) {substr(NGS_reads[x],i,i+read_length-1)}) # begin to subdivide the big alignment into subsets, each has the length of read_length
subset_small <- subset_original[which(as.character(lapply(1:total_reads, function(x) {substr(subset_original[x],1,10)}))!="----------")]
subset_smaller <- subset_small[which(as.character(lapply(1:length(subset_small), function(x) {substr(subset_small[x],200,209)}))!="----------")]
subset_smallest <- subset_smaller[which(lapply(1:total_reads, function(x) {str_count(substr(subset_smaller[x],1,200),"A")>25})==TRUE)]
cat(verbose, paste0("Number of reads in subset ", which(begin_number==i), " = ",length(subset_smallest),"\n"))
if (length(subset_smallest)<=2) stop("This subset has too few reads (<2). Enter a new value for the parameter 'overlap' and subset the dataset again!")
write.fasta(sequences = subset_smallest, names = 1:length(subset_smallest), file.out = paste0("Subset_",which(begin_number==i),"_downsized.fasta"))
}
Subsets <- str_sort(list.files(pattern="_downsized.fasta"), numeric = TRUE)
# for each of the subset_1, 2, 3...
for (i in 1:length(Subsets)) {
cat("********************************************\n")
Subset <- as.character.DNAbin(read.FASTA(file=Subsets[i], type = "DNA"))
cat(paste0("Clustering analyses for the Subset ", i,"\n"))
# find the threshold range for OTU to find the major clusters (number=copy_number) for each subset
for (m in seq(0.3,1, by = 0.1)) {
Subset_OTU <- otu(Subset, k = 5, threshold = m, method = "central", nstart = 20)
cat(verbose, paste0("threshold = ",m),"\n")
cat(verbose, unique(Subset_OTU),"\n")
if (length(unique(Subset_OTU))>=copy_number) {break}
}
# try different threshold values in the range found above
for (j in seq(m-0.09,m, by = 0.01)) {
Subset_OTU <- otu(Subset, k = 5, threshold = j, method = "central", nstart = 20)
cat(verbose, paste0("threshold = ",j),"\n")
cat(verbose, unique(Subset_OTU),"\n")
if (length(unique(Subset_OTU))>=copy_number) {break}
}
reads_each_cluster <- sapply(unique(Subset_OTU), function(x) length(which(Subset_OTU==x)))
cat(paste0("Best threshold found = ",j),"\n")
cat(unique(Subset_OTU),"\n")
cat("Number of reads in each cluster\n")
cat(reads_each_cluster,"\n")
for (l in (1:copy_number)) {
Picked_cluster <- Subset[which(Subset_OTU==unique(Subset_OTU)[which(reads_each_cluster==sort(reads_each_cluster)[length(unique(Subset_OTU))-l+1])])]
seqinr::write.fasta(sequences = Picked_cluster, names = labels(Picked_cluster), file.out = paste0("Subset_",i,"_cluster_",l,".fasta"))
cat(paste0("Number of reads in picked cluster ",l, " = ", length(Picked_cluster),"\n"))
# calcuate the consensus sequence for the clusters of the subset
write.fasta(sequences = paste0(c(as.character(rep("-",(read_length-overlap)*(i-1))),as.character(ConsensusSequence(readDNAStringSet(paste0("Subset_",i,"_cluster_",l,".fasta"),
format="fasta",nrec=-1L, skip=0L),threshold = 0.4, ambiguity = TRUE, noConsensusChar = "N")[1])), collapse=''),
names = paste0("Subset_",i,"_cluster_",l,"_consensus"), file.out = paste0("Subset_",i,"_cluster_",l,"_consensus.fasta"))
}
}
# put together all the consensus sequences from all subsets into one file
Consensus_list <- str_sort(list.files(pattern="_consensus.fasta"), numeric = TRUE)
All_consensus <- lapply(1:length(Consensus_list), function (x) read.fasta(file = Consensus_list[x], seqtype = "DNA",
as.string = TRUE,forceDNAtolower = FALSE,set.attributes = FALSE, whole.header = TRUE))
filename_short <- gsub("[:.:].*","", filename) # remove file extensions, e.g. ".fasta", ".txt"
# move subset files into the intermediate files folder
dir.create(paste0(filename_short,"_intermediate_files"))
invisible(file.copy(list.files(pattern="Subset_"), paste0(filename_short,"_intermediate_files")))  # use "invisible" so that output do not show here
unlink(list.files(pattern="Subset_"))
write.fasta(sequences=All_consensus, names=Consensus_list, file.out=paste0(filename_short,"_combined_consensus_",copy_number,"copies_overlap",overlap,".txt"))
cat("Run finished!\n")
beep(sound = 1, expr = NULL) # make a sound when run finishes
options("error" = error_log_function)
sink() # turn off log
setwd("~/Desktop/Copysep")
on(verbose)
sink("log.txt", append=FALSE, split=TRUE) # begin to record log
error_log_function <- function() {
cat(geterrmessage(), file="Error_log.txt", append=T)
}
filename="Sucker.fasta"
copy_number=2
read_length=300
overlap=225
lower_threshold=0.45
if (copy_number<=1) stop ("The expected copy number must be a number larger than one!")
if (read_length<250) warning ("This method is designed for read length 250bp or longer. Short reads can easily result in chimeric sequences.")
NGS_reads <- read.fasta(file = filename,seqtype = "DNA", as.string = TRUE,forceDNAtolower = FALSE,set.attributes = FALSE)
total_reads <- length(NGS_reads); cat(paste0("Total number of reads imported = ",total_reads,"\n"))
alignment_length <- nchar(NGS_reads[[1]]); cat(paste0("Length of the alignment = ",alignment_length,"\n"))
cat(paste0("Read length = ",read_length,"\n"))
cat(paste0("Overlap between adjacent subsets = ",overlap,"\n"))
if (overlap>=read_length) stop("Overlap between adjacent subsets must be smaller than the read length!")
begin_number <- seq(1,alignment_length-200, by=read_length-overlap); cat("Beginning position of each subset","\n"); cat(begin_number,"\n")
end_number <- begin_number+read_length-1; cat("Ending position of each subset\n"); cat(end_number,"\n")
number_of_subsets <- length(begin_number); cat(paste0("Total number of subsets = ",number_of_subsets,"\n"))
for (i in begin_number) {
subset_original <- lapply(1:total_reads, function(x) {substr(NGS_reads[x],i,i+read_length-1)}) # begin to subdivide the big alignment into subsets, each has the length of read_length
subset_small <- subset_original[which(as.character(lapply(1:total_reads, function(x) {substr(subset_original[x],1,10)}))!="----------")]
subset_smaller <- subset_small[which(as.character(lapply(1:length(subset_small), function(x) {substr(subset_small[x],200,209)}))!="----------")]
subset_smallest <- subset_smaller[which(lapply(1:total_reads, function(x) {str_count(substr(subset_smaller[x],1,200),"A")>25})==TRUE)]
cat(verbose, paste0("Number of reads in subset ", which(begin_number==i), " = ",length(subset_smallest),"\n"))
if (length(subset_smallest)<=2) stop("This subset has too few reads (<2). Enter a new value for the parameter 'overlap' and subset the dataset again!")
write.fasta(sequences = subset_smallest, names = 1:length(subset_smallest), file.out = paste0("Subset_",which(begin_number==i),"_downsized.fasta"))
}
Subsets <- str_sort(list.files(pattern="_downsized.fasta"), numeric = TRUE)
# for each of the subset_1, 2, 3...
for (i in 1:length(Subsets)) {
cat("********************************************\n")
Subset <- as.character.DNAbin(read.FASTA(file=Subsets[i], type = "DNA"))
cat(paste0("Clustering analyses for the Subset ", i,"\n"))
# find the threshold range for OTU to find the major clusters (number=copy_number) for each subset
for (m in seq(0.3,1, by = 0.1)) {
Subset_OTU <- otu(Subset, k = 5, threshold = m, method = "central", nstart = 20)
cat(verbose, paste0("threshold = ",m),"\n")
cat(verbose, unique(Subset_OTU),"\n")
if (length(unique(Subset_OTU))>=copy_number) {break}
}
# try different threshold values in the range found above
for (j in seq(m-0.09,m, by = 0.01)) {
Subset_OTU <- otu(Subset, k = 5, threshold = j, method = "central", nstart = 20)
cat(verbose, paste0("threshold = ",j),"\n")
cat(verbose, unique(Subset_OTU),"\n")
if (length(unique(Subset_OTU))>=copy_number) {break}
}
reads_each_cluster <- sapply(unique(Subset_OTU), function(x) length(which(Subset_OTU==x)))
cat(paste0("Best threshold found = ",j),"\n")
cat(unique(Subset_OTU),"\n")
cat("Number of reads in each cluster\n")
cat(reads_each_cluster,"\n")
for (l in (1:copy_number)) {
Picked_cluster <- Subset[which(Subset_OTU==unique(Subset_OTU)[which(reads_each_cluster==sort(reads_each_cluster)[length(unique(Subset_OTU))-l+1])])]
seqinr::write.fasta(sequences = Picked_cluster, names = labels(Picked_cluster), file.out = paste0("Subset_",i,"_cluster_",l,".fasta"))
cat(paste0("Number of reads in picked cluster ",l, " = ", length(Picked_cluster),"\n"))
# calcuate the consensus sequence for the clusters of the subset
write.fasta(sequences = paste0(c(as.character(rep("-",(read_length-overlap)*(i-1))),as.character(ConsensusSequence(readDNAStringSet(paste0("Subset_",i,"_cluster_",l,".fasta"),
format="fasta",nrec=-1L, skip=0L),threshold = 0.4, ambiguity = TRUE, noConsensusChar = "N")[1])), collapse=''),
names = paste0("Subset_",i,"_cluster_",l,"_consensus"), file.out = paste0("Subset_",i,"_cluster_",l,"_consensus.fasta"))
}
}
# put together all the consensus sequences from all subsets into one file
Consensus_list <- str_sort(list.files(pattern="_consensus.fasta"), numeric = TRUE)
All_consensus <- lapply(1:length(Consensus_list), function (x) read.fasta(file = Consensus_list[x], seqtype = "DNA",
as.string = TRUE,forceDNAtolower = FALSE,set.attributes = FALSE, whole.header = TRUE))
filename_short <- gsub("[:.:].*","", filename) # remove file extensions, e.g. ".fasta", ".txt"
# move subset files into the intermediate files folder
dir.create(paste0(filename_short,"_intermediate_files"))
invisible(file.copy(list.files(pattern="Subset_"), paste0(filename_short,"_intermediate_files")))  # use "invisible" so that output do not show here
unlink(list.files(pattern="Subset_"))
write.fasta(sequences=All_consensus, names=Consensus_list, file.out=paste0(filename_short,"_combined_consensus_",copy_number,"copies_overlap",overlap,".txt"))
cat("Run finished!\n")
beep(sound = 1, expr = NULL) # make a sound when run finishes
options("error" = error_log_function)
sink() # turn off log
on(verbose)
sink("log.txt", append=FALSE, split=TRUE) # begin to record log
error_log_function <- function() {
cat(geterrmessage(), file="Error_log.txt", append=T)
}
filename="Sucker.fasta"
copy_number=2
read_length=300
overlap=225
lower_threshold=0.45
if (copy_number<=1) stop ("The expected copy number must be a number larger than one!")
if (read_length<250) warning ("This method is designed for read length 250bp or longer. Short reads can easily result in chimeric sequences.")
NGS_reads <- read.fasta(file = filename,seqtype = "DNA", as.string = TRUE,forceDNAtolower = FALSE,set.attributes = FALSE)
total_reads <- length(NGS_reads); cat(paste0("Total number of reads imported = ",total_reads,"\n"))
alignment_length <- nchar(NGS_reads[[1]]); cat(paste0("Length of the alignment = ",alignment_length,"\n"))
cat(paste0("Read length = ",read_length,"\n"))
cat(paste0("Overlap between adjacent subsets = ",overlap,"\n"))
if (overlap>=read_length) stop("Overlap between adjacent subsets must be smaller than the read length!")
begin_number <- seq(1,alignment_length-200, by=read_length-overlap); cat("Beginning position of each subset","\n"); cat(begin_number,"\n")
end_number <- begin_number+read_length-1; cat("Ending position of each subset\n"); cat(end_number,"\n")
number_of_subsets <- length(begin_number); cat(paste0("Total number of subsets = ",number_of_subsets,"\n"))
for (i in begin_number) {
subset_original <- lapply(1:total_reads, function(x) {substr(NGS_reads[x],i,i+read_length-1)}) # begin to subdivide the big alignment into subsets, each has the length of read_length
subset_small <- subset_original[which(as.character(lapply(1:total_reads, function(x) {substr(subset_original[x],1,10)}))!="----------")]
subset_smaller <- subset_small[which(as.character(lapply(1:length(subset_small), function(x) {substr(subset_small[x],200,209)}))!="----------")]
subset_smallest <- subset_smaller[which(lapply(1:total_reads, function(x) {str_count(substr(subset_smaller[x],1,200),"A")>25})==TRUE)]
cat(verbose, paste0("Number of reads in subset ", which(begin_number==i), " = ",length(subset_smallest),"\n"))
if (length(subset_smallest)<=2) stop("This subset has too few reads (<2). Enter a new value for the parameter 'overlap' and subset the dataset again!")
write.fasta(sequences = subset_smallest, names = 1:length(subset_smallest), file.out = paste0("Subset_",which(begin_number==i),"_downsized.fasta"))
}
Subsets <- str_sort(list.files(pattern="_downsized.fasta"), numeric = TRUE)
# for each of the subset_1, 2, 3...
for (i in 1:length(Subsets)) {
cat("********************************************\n")
Subset <- as.character.DNAbin(read.FASTA(file=Subsets[i], type = "DNA"))
cat(paste0("Clustering analyses for the Subset ", i,"\n"))
# find the threshold range for OTU to find the major clusters (number=copy_number) for each subset
for (m in seq(0.3,1, by = 0.1)) {
Subset_OTU <- otu(Subset, k = 5, threshold = m, method = "central", nstart = 20)
cat(verbose, paste0("threshold = ",m),"\n")
cat(verbose, unique(Subset_OTU),"\n")
if (length(unique(Subset_OTU))>=copy_number) {break}
}
# try different threshold values in the range found above
for (j in seq(m-0.09,m, by = 0.01)) {
Subset_OTU <- otu(Subset, k = 5, threshold = j, method = "central", nstart = 20)
cat(verbose, paste0("threshold = ",j),"\n")
cat(verbose, unique(Subset_OTU),"\n")
if (length(unique(Subset_OTU))>=copy_number) {break}
}
reads_each_cluster <- sapply(unique(Subset_OTU), function(x) length(which(Subset_OTU==x)))
cat(paste0("Best threshold found = ",j),"\n")
cat(unique(Subset_OTU),"\n")
cat("Number of reads in each cluster\n")
cat(reads_each_cluster,"\n")
for (l in (1:copy_number)) {
Picked_cluster <- Subset[which(Subset_OTU==unique(Subset_OTU)[which(reads_each_cluster==sort(reads_each_cluster)[length(unique(Subset_OTU))-l+1])])]
seqinr::write.fasta(sequences = Picked_cluster, names = labels(Picked_cluster), file.out = paste0("Subset_",i,"_cluster_",l,".fasta"))
cat(paste0("Number of reads in picked cluster ",l, " = ", length(Picked_cluster),"\n"))
# calcuate the consensus sequence for the clusters of the subset
write.fasta(sequences = paste0(c(as.character(rep("-",(read_length-overlap)*(i-1))),as.character(ConsensusSequence(readDNAStringSet(paste0("Subset_",i,"_cluster_",l,".fasta"),
format="fasta",nrec=-1L, skip=0L),threshold = 0.4, ambiguity = TRUE, noConsensusChar = "N")[1])), collapse=''),
names = paste0("Subset_",i,"_cluster_",l,"_consensus"), file.out = paste0("Subset_",i,"_cluster_",l,"_consensus.fasta"))
}
}
# put together all the consensus sequences from all subsets into one file
Consensus_list <- str_sort(list.files(pattern="_consensus.fasta"), numeric = TRUE)
All_consensus <- lapply(1:length(Consensus_list), function (x) read.fasta(file = Consensus_list[x], seqtype = "DNA",
as.string = TRUE,forceDNAtolower = FALSE,set.attributes = FALSE, whole.header = TRUE))
filename_short <- gsub("[:.:].*","", filename) # remove file extensions, e.g. ".fasta", ".txt"
# move subset files into the intermediate files folder
dir.create(paste0(filename_short,"_intermediate_files"))
invisible(file.copy(list.files(pattern="Subset_"), paste0(filename_short,"_intermediate_files")))  # use "invisible" so that output do not show here
unlink(list.files(pattern="Subset_"))
write.fasta(sequences=All_consensus, names=Consensus_list, file.out=paste0(filename_short,"_combined_consensus_",copy_number,"copies_overlap",overlap,".txt"))
cat("Run finished!\n")
beep(sound = 1, expr = NULL) # make a sound when run finishes
options("error" = error_log_function)
sink() # turn off log
# import the read alignment exported from Geneious
library(ape)
library(seqinr)
library(stringr)
library(kmer)
library(DECIPHER)
library(beepr)
library('R.utils')
on(verbose)
sink("log.txt", append=FALSE, split=TRUE) # begin to record log
error_log_function <- function() {
cat(geterrmessage(), file="Error_log.txt", append=T)
}
filename="Sucker.fasta"
copy_number=2
read_length=300
overlap=225
lower_threshold=0.45
if (copy_number<=1) stop ("The expected copy number must be a number larger than one!")
if (read_length<250) warning ("This method is designed for read length 250bp or longer. Short reads can easily result in chimeric sequences.")
NGS_reads <- read.fasta(file = filename,seqtype = "DNA", as.string = TRUE,forceDNAtolower = FALSE,set.attributes = FALSE)
total_reads <- length(NGS_reads); cat(paste0("Total number of reads imported = ",total_reads,"\n"))
alignment_length <- nchar(NGS_reads[[1]]); cat(paste0("Length of the alignment = ",alignment_length,"\n"))
cat(paste0("Read length = ",read_length,"\n"))
cat(paste0("Overlap between adjacent subsets = ",overlap,"\n"))
if (overlap>=read_length) stop("Overlap between adjacent subsets must be smaller than the read length!")
begin_number <- seq(1,alignment_length-200, by=read_length-overlap); cat("Beginning position of each subset","\n"); cat(begin_number,"\n")
end_number <- begin_number+read_length-1; cat("Ending position of each subset\n"); cat(end_number,"\n")
number_of_subsets <- length(begin_number); cat(paste0("Total number of subsets = ",number_of_subsets,"\n"))
for (i in begin_number) {
subset_original <- lapply(1:total_reads, function(x) {substr(NGS_reads[x],i,i+read_length-1)}) # begin to subdivide the big alignment into subsets, each has the length of read_length
subset_small <- subset_original[which(as.character(lapply(1:total_reads, function(x) {substr(subset_original[x],1,10)}))!="----------")]
subset_smaller <- subset_small[which(as.character(lapply(1:length(subset_small), function(x) {substr(subset_small[x],200,209)}))!="----------")]
subset_smallest <- subset_smaller[which(lapply(1:total_reads, function(x) {str_count(substr(subset_smaller[x],1,200),"A")>25})==TRUE)]
cat(verbose, paste0("Number of reads in subset ", which(begin_number==i), " = ",length(subset_smallest),"\n"))
if (length(subset_smallest)<=2) stop("This subset has too few reads (<2). Enter a new value for the parameter 'overlap' and subset the dataset again!")
write.fasta(sequences = subset_smallest, names = 1:length(subset_smallest), file.out = paste0("Subset_",which(begin_number==i),"_downsized.fasta"))
}
Subsets <- str_sort(list.files(pattern="_downsized.fasta"), numeric = TRUE)
# for each of the subset_1, 2, 3...
for (i in 1:length(Subsets)) {
cat("********************************************\n")
Subset <- as.character.DNAbin(read.FASTA(file=Subsets[i], type = "DNA"))
cat(paste0("Clustering analyses for the Subset ", i,"\n"))
# find the threshold range for OTU to find the major clusters (number=copy_number) for each subset
for (m in seq(0.3,1, by = 0.1)) {
Subset_OTU <- otu(Subset, k = 5, threshold = m, method = "central", nstart = 20)
cat(verbose, paste0("threshold = ",m),"\n")
cat(verbose, unique(Subset_OTU),"\n")
if (length(unique(Subset_OTU))>=copy_number) {break}
}
# try different threshold values in the range found above
for (j in seq(m-0.09,m, by = 0.01)) {
Subset_OTU <- otu(Subset, k = 5, threshold = j, method = "central", nstart = 20)
cat(verbose, paste0("threshold = ",j),"\n")
cat(verbose, unique(Subset_OTU),"\n")
if (length(unique(Subset_OTU))>=copy_number) {break}
}
reads_each_cluster <- sapply(unique(Subset_OTU), function(x) length(which(Subset_OTU==x)))
cat(paste0("Best threshold found = ",j),"\n")
cat(unique(Subset_OTU),"\n")
cat("Number of reads in each cluster\n")
cat(reads_each_cluster,"\n")
for (l in (1:copy_number)) {
Picked_cluster <- Subset[which(Subset_OTU==unique(Subset_OTU)[which(reads_each_cluster==sort(reads_each_cluster)[length(unique(Subset_OTU))-l+1])])]
seqinr::write.fasta(sequences = Picked_cluster, names = labels(Picked_cluster), file.out = paste0("Subset_",i,"_cluster_",l,".fasta"))
cat(paste0("Number of reads in picked cluster ",l, " = ", length(Picked_cluster),"\n"))
# calcuate the consensus sequence for the clusters of the subset
write.fasta(sequences = paste0(c(as.character(rep("-",(read_length-overlap)*(i-1))),as.character(ConsensusSequence(readDNAStringSet(paste0("Subset_",i,"_cluster_",l,".fasta"),
format="fasta",nrec=-1L, skip=0L),threshold = 0.4, ambiguity = TRUE, noConsensusChar = "N")[1])), collapse=''),
names = paste0("Subset_",i,"_cluster_",l,"_consensus"), file.out = paste0("Subset_",i,"_cluster_",l,"_consensus.fasta"))
}
}
# put together all the consensus sequences from all subsets into one file
Consensus_list <- str_sort(list.files(pattern="_consensus.fasta"), numeric = TRUE)
All_consensus <- lapply(1:length(Consensus_list), function (x) read.fasta(file = Consensus_list[x], seqtype = "DNA",
as.string = TRUE,forceDNAtolower = FALSE,set.attributes = FALSE, whole.header = TRUE))
filename_short <- gsub("[:.:].*","", filename) # remove file extensions, e.g. ".fasta", ".txt"
# move subset files into the intermediate files folder
dir.create(paste0(filename_short,"_intermediate_files"))
invisible(file.copy(list.files(pattern="Subset_"), paste0(filename_short,"_intermediate_files")))  # use "invisible" so that output do not show here
unlink(list.files(pattern="Subset_"))
write.fasta(sequences=All_consensus, names=Consensus_list, file.out=paste0(filename_short,"_combined_consensus_",copy_number,"copies_overlap",overlap,".txt"))
cat("Run finished!\n")
beep(sound = 1, expr = NULL) # make a sound when run finishes
options("error" = error_log_function)
sink() # turn off log
setwd("~/Desktop/copyseparator")
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
devtools::document()
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
library(copyseparator)
copy_separate("Sucker.fasta",2,300)
devtools::document()
devtools::document()
library(copyseparator)
copy_separate("Sucker.fasta",2,300,0)
copy_separate("Sucker.fasta",2,300,225,0)
